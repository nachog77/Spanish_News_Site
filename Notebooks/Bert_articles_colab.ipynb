{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish News Article's origin site determination\n",
    "## Using a Bert pre-trained multi-language model enhanced by Transfer Learning\n",
    "## Trained on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8f3-h-V-v55"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "from matplotlib.colors import LogNorm\n",
    "from operator import itemgetter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jr1VI3mVKVfe"
   },
   "outputs": [],
   "source": [
    "#Configuration parameters\n",
    "maxlen=500 #Maximum length of texts from the beggining of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8608,
     "status": "ok",
     "timestamp": 1566562647943,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "R7aNEclA-v59",
    "outputId": "592fd9fa-1006-42e3-8e75-2c89b4000bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-pretrained-bert==0.4.0 in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.16.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.4.0) (4.28.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.4.0) (2.21.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.9.205)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (2019.6.16)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (2.8)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.4.0) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.4.0) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.205 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.4.0) (1.12.205)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch-pretrained-bert==0.4.0) (2.5.3)\n",
      "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch-pretrained-bert==0.4.0) (0.14)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.205->boto3->pytorch-pretrained-bert==0.4.0) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11684,
     "status": "ok",
     "timestamp": 1566562651027,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "aGSV03bl-v5_",
    "outputId": "40930823-ed36-4ccc-ced5-272cf4d87d4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForSequenceClassification, BertAdam\n",
    "from tqdm import tqdm_notebook,trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11676,
     "status": "ok",
     "timestamp": 1566562651027,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "nw4XUamA-v6C",
    "outputId": "8481be11-0e4d-418b-cc76-0d534ca1edd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#Mounting Google drive (Requires key)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g9vlYQNE-v6h"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66011,
     "status": "ok",
     "timestamp": 1566562705507,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "Jg-IoF06-v6j",
    "outputId": "1fbe2d37-724f-4987-f223-b3a1a9c05892"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16293,
     "status": "ok",
     "timestamp": 1566562655654,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "TLSK1Cev-v6F",
    "outputId": "79c70934-2123-4f2f-f4ed-1ce3032f76fb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pais</th>\n",
       "      <th>domain</th>\n",
       "      <th>site</th>\n",
       "      <th>tipo</th>\n",
       "      <th>autor</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190182</td>\n",
       "      <td>US</td>\n",
       "      <td>1868</td>\n",
       "      <td>el-nacional.com</td>\n",
       "      <td>news</td>\n",
       "      <td>Juan Carlos D Az</td>\n",
       "      <td>Un país sin futuro ni oportunidades Tweet: Jua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323503</td>\n",
       "      <td>ES</td>\n",
       "      <td>2957</td>\n",
       "      <td>telecinco.es</td>\n",
       "      <td>news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>José Manuel López dice que la \"hoja de ruta\" e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>333942</td>\n",
       "      <td>ES</td>\n",
       "      <td>1487</td>\n",
       "      <td>abc.es</td>\n",
       "      <td>news</td>\n",
       "      <td>(lavozdigital)</td>\n",
       "      <td>TURISMO Los turistas se dan de bruces con la r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148948</td>\n",
       "      <td>ES</td>\n",
       "      <td>4291</td>\n",
       "      <td>eldiario.es</td>\n",
       "      <td>news</td>\n",
       "      <td>esglobal</td>\n",
       "      <td>Un hombre ha resultado muerto al ser arrastrad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165938</td>\n",
       "      <td>ES</td>\n",
       "      <td>6093</td>\n",
       "      <td>coches.net</td>\n",
       "      <td>news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La pregunta no puede contener URLs Tu nombre T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                              texto\n",
       "0      190182  ...  Un país sin futuro ni oportunidades Tweet: Jua...\n",
       "1      323503  ...  José Manuel López dice que la \"hoja de ruta\" e...\n",
       "2      333942  ...  TURISMO Los turistas se dan de bruces con la r...\n",
       "3      148948  ...  Un hombre ha resultado muerto al ser arrastrad...\n",
       "4      165938  ...  La pregunta no puede contener URLs Tu nombre T...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Introduce path to CSV with article's text as created by Preprocess Notebook\n",
    "dframe=pd.read_csv(\"PATH_TO_CSV\")\n",
    "dframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-D_H38jOkHs"
   },
   "outputs": [],
   "source": [
    "dframe=dframe[['site','texto']]\n",
    "dframe.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16278,
     "status": "ok",
     "timestamp": 1566562655660,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "omE61cc9zG3Z",
    "outputId": "e395a4c9-43fc-4373-f8cf-ab22e2f289a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eleconomista.es       21873\n",
       "coches.net            11508\n",
       "europapress.es        11031\n",
       "eldiario.es           10384\n",
       "telecinco.es          10206\n",
       "abc.es                 9749\n",
       "milenio.com            8946\n",
       "yahoo.com              7183\n",
       "meneame.net            6651\n",
       "elcomercio.pe          5737\n",
       "biobiochile.cl         5555\n",
       "lanacion.com.ar        5367\n",
       "elpais.com             5262\n",
       "clarin.com             5257\n",
       "boe.es                 4651\n",
       "el-nacional.com        4515\n",
       "debate.com.mx          4268\n",
       "elmundo.es             4249\n",
       "mundodeportivo.com     4179\n",
       "Name: site, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe.site.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16269,
     "status": "ok",
     "timestamp": 1566562655662,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "s2q1mNsb-v6K",
    "outputId": "81554023-6edf-446c-aff1-b0f9488f70d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146571"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InCvXU2I-v6M"
   },
   "outputs": [],
   "source": [
    "\n",
    "dframe['texto']=dframe.texto.apply(lambda x: str.lower(x))\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "dframe['texto']=dframe.texto.apply(lambda x: x.translate(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2h7hn3w-v6P"
   },
   "outputs": [],
   "source": [
    "dframe['words']=dframe.texto.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mP7uzz94fzPH"
   },
   "outputs": [],
   "source": [
    "dframe['len']=dframe['words'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TcHxcOpgFjj"
   },
   "outputs": [],
   "source": [
    "dframe=dframe[dframe.len>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55610,
     "status": "ok",
     "timestamp": 1566562695044,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "EZBtWApz-v6R",
    "outputId": "bbfc8b6d-21be-43ec-b242-e4a50ab9a665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 19891\n"
     ]
    }
   ],
   "source": [
    "print ('Maximum sequence length:', max([len(s) for s in dframe.words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56001,
     "status": "ok",
     "timestamp": 1566562695443,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "wjnCk5cG-v6U",
    "outputId": "33aa99b5-d673-4c88-f20a-a3c1f7243304"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nui9sybltWt8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in dframe.words], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66051,
     "status": "ok",
     "timestamp": 1566562705502,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "8r01rFOz-v6X",
    "outputId": "031314cf-bb7d-4036-fba9-4a5df3ac028c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548242"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words= [item for sublist in list(dframe.words) for item in sublist]\n",
    "words = list(set(words))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words=len(words)\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66045,
     "status": "ok",
     "timestamp": 1566562705503,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "P-aGkvAz-v6a",
    "outputId": "43f412f4-3c26-4970-8ae4-157ce624f525"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(dframe[\"site\"].values))\n",
    "n_tags = len(tags)\n",
    "n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66038,
     "status": "ok",
     "timestamp": 1566562705504,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "uVoVt64c-v6d",
    "outputId": "1a82e3d4-7e2e-4dab-bec9-58475ad81606"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lanacion.com.ar',\n",
       " 'elmundo.es',\n",
       " 'milenio.com',\n",
       " 'debate.com.mx',\n",
       " 'elcomercio.pe',\n",
       " 'eldiario.es',\n",
       " 'telecinco.es',\n",
       " 'europapress.es',\n",
       " 'mundodeportivo.com',\n",
       " 'clarin.com',\n",
       " 'eleconomista.es',\n",
       " 'biobiochile.cl',\n",
       " 'elpais.com',\n",
       " 'abc.es',\n",
       " 'coches.net',\n",
       " 'meneame.net',\n",
       " 'yahoo.com',\n",
       " 'el-nacional.com',\n",
       " 'boe.es']"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Mdy3zfV-v6f"
   },
   "outputs": [],
   "source": [
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1FPTAhwvhOK"
   },
   "outputs": [],
   "source": [
    "#Save assignation of sites to tags for posterior use \n",
    "#Introduce path where to save\n",
    "pickle_out = open('OUTPUT_PATH/tag_dict.pkl',\"wb\")\n",
    "pickle.dump(tag2idx, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Tokenization using Bert model obtained from https://github.com/google-research/bert/blob/master/multilingual.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZLXB9Up-v6m"
   },
   "outputs": [],
   "source": [
    "#Introduce path to model file\n",
    "tokenizer = BertTokenizer.from_pretrained('PATH_TO_MODEL', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 102972,
     "status": "ok",
     "timestamp": 1566562742482,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "EdhQCFul-v6o",
    "outputId": "d022f7f2-481d-424c-8e0a-222c714fbe59"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316beef522034bd894409b4701599a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=548242), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokens={}\n",
    "for w in tqdm_notebook(words):\n",
    "    token=tokenizer.tokenize(w)\n",
    "    tokens[w]=token   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "barNQ42t-v6q"
   },
   "outputs": [],
   "source": [
    "def tokenize_sentence(ls,tokens):\n",
    "    t=[]\n",
    "    for l in ls:\n",
    "        t=t+tokens[l]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgd78ACJ-v6u"
   },
   "outputs": [],
   "source": [
    "dframe['tokens']=dframe.words.apply(lambda x: tokenize_sentence(x,tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VmzYkwoE-v6x"
   },
   "outputs": [],
   "source": [
    "dframe['input']=dframe.tokens.apply(lambda x: tokenizer.convert_tokens_to_ids(x))\n",
    "dframe['label']=dframe.site.apply(lambda x:tag2idx[x] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8uMajhbOznx"
   },
   "outputs": [],
   "source": [
    "inputs=pad_sequences(dframe.input,maxlen=maxlen, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAOEzcD2RJsn"
   },
   "outputs": [],
   "source": [
    "#Split data into train, validation and test sets\n",
    "tr_inputs, aux_inputs, tr_tags, aux_tags= train_test_split(inputs,list(dframe.label), random_state=1977, test_size=0.05, stratify=dframe.label)\n",
    "val_inputs, test_inputs, val_tags, test_tags = train_test_split(aux_inputs,aux_tags, random_state=1977, test_size=0.5, stratify=aux_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model for Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFcSSP7s-v7V"
   },
   "outputs": [],
   "source": [
    "#Tensor inputs\n",
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "test_tags = torch.tensor(test_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcJSNrl0-v7X"
   },
   "outputs": [],
   "source": [
    "bs = 8\n",
    "train_data = TensorDataset(tr_inputs, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bd9pAOCO-v7Z"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model= BertForSequenceClassification.from_pretrained('bert-base-multilingual-uncased', num_labels=n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 323859,
     "status": "ok",
     "timestamp": 1566562963438,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "ug1yuG1N-v7c",
    "outputId": "0f27a7c5-101f-437a-c95c-3915644e6186"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=19, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MpMXo6nJ-v7g"
   },
   "outputs": [],
   "source": [
    "#Prepare model for parameter tunning\n",
    "epochs = 10\n",
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "num_train_optimization_steps= int(len(tr_inputs) / bs) * epochs\n",
    "optimizer = BertAdam(optimizer_grouped_parameters, lr=3e-6,warmup=0.1,t_total=num_train_optimization_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uwvw-Jlg-v7i"
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    return np.sum(np.argmax(preds, axis=1) == labels) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1093577,
     "status": "ok",
     "timestamp": 1566460306869,
     "user": {
      "displayName": "José Ignacio Garzón",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDlMrVi-iq3NKa8U5ypeyO5xyVpOUaNe12cNq6E=s64",
      "userId": "07926305101285734067"
     },
     "user_tz": -120
    },
    "id": "VipkYvvK-v7k",
    "outputId": "4a5693bf-a98f-4913-95e6-cb970ec60776"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.8381378264967987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  10%|█         | 1/10 [1:01:08<9:10:13, 3668.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.687086489523342\n",
      "Validation Accuracy: 0.22298034934497818\n",
      "Train loss: 2.607569458502493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  20%|██        | 2/10 [2:02:18<8:09:11, 3668.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.468813300653316\n",
      "Validation Accuracy: 0.24399563318777293\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    epoch_sample=list(enumerate(train_dataloader))\n",
    "    train_size=int(len(epoch_sample)/10)\n",
    "    epoch_sample=epoch_sample[0:train_size]\n",
    "    for step, batch in epoch_sample:\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None,labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
    "            logits = model(b_input_ids, token_type_ids=None)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in logits])\n",
    "        true_labels.append(label_ids)\n",
    "        #print(\"prediction: \"+str(np.argmax(logits, axis=1)))\n",
    "        #print(\"label*****: \"+str(label_ids))\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYE0sANhJUbl"
   },
   "outputs": [],
   "source": [
    "test_data = TensorDataset(test_inputs, test_tags)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mnhUWJL3IbBl"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = 0, 0\n",
    "nb_test_steps=0\n",
    "predictions , true_labels = [], []\n",
    "for batch in test_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_test_loss = model(b_input_ids, token_type_ids=None, labels=b_labels)\n",
    "            logits = model(b_input_ids, token_type_ids=None)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in logits])\n",
    "        #print(\"prediction: \"+str(np.argmax(logits, axis=1)))\n",
    "        #print(\"label*****: \"+str(label_ids))\n",
    "        tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        test_loss += tmp_test_loss.mean().item()\n",
    "        test_accuracy += tmp_test_accuracy\n",
    "        \n",
    "        nb_test_steps += 1\n",
    "test_loss = test_loss/nb_test_steps\n",
    "print(\"Test loss: {}\".format(test_loss))\n",
    "print(\"Test Accuracy: {}\".format(test_accuracy/nb_test_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model parameters for posterior use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKyX4jDxAxBn"
   },
   "outputs": [],
   "source": [
    "state_dict_with_prefix={}\n",
    "for key,value in model.named_parameters():\n",
    "    state_dict_with_prefix[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BewuSAyRAyss"
   },
   "outputs": [],
   "source": [
    "# Introduce path where to save model\n",
    "pickle_out = open('OUTPUT_PATH/model.pkl',\"wb\")\n",
    "pickle.dump(state_dict_with_prefix, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uea4MGz8-v7m"
   },
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Bert_articles_colab.ipynb",
   "provenance": [
    {
     "file_id": "1JmWqRNu4cXY0WROZDmgeRFPERguhalIN",
     "timestamp": 1566390450844
    },
    {
     "file_id": "1sEDFCwBC8P1Yj3krwj9nkwB5fSHItLsL",
     "timestamp": 1566286993066
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python (python3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
